{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ofici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code processes geospatial data related to population, precipitation, and droughts. It loads population\n",
    " data from TIFF files, precipitation data from ERA5 NetCDF files, and World Bank country data.\n",
    " It rasterizes vector datasets, computes zonal statistics, and compiles these statistics over time.\n",
    " It generates annual drought data from SPI and SPEI indices, saving the results in NetCDF and Feather\n",
    " files for further analysis.\n",
    "\n",
    "Input:\n",
    "- ERA5_monthly_1970-2021_SPI-SPEI.nc\n",
    "- Files in D:\\Datasets\\Gridded Population of the World\n",
    "- world_bank_adm2.zip\n",
    "\n",
    "Output:\n",
    "- ERA5_yearly_1970-2021_SPI-SPEI.nc (intermediate files)\n",
    "- ERA5_droughts_yearly.nc (final files)\n",
    "- WB_country_grid.nc\n",
    "- WB_country_IDs.feather\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "New packages used:\n",
    "\n",
    "- hashlib: defines a programming interface for accessing various cryptographic hash algorithms.\n",
    "- xrspatial: spatial analysis functions integrated with Xarray, useful for raster analysis and\n",
    " geographic data manipulation\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "\n",
    "import dask\n",
    "import xarray as xr\n",
    "import xrspatial\n",
    "from dask.diagnostics import ProgressBar\n",
    "from geocube.api.core import make_geocube\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "PATH = \"D:\\World Bank\\CLIENT v2\"\n",
    "DATA_RAW = rf\"{PATH}\\Data\\Data_raw\"\n",
    "DATA_PROC = rf\"{PATH}\\Data\\Data_proc\"\n",
    "DATA_OUT = rf\"{PATH}\\Data\\Data_out\"\n",
    "GPW_PATH = rf\"D:\\Datasets\\Gridded Population of the World\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# floods = pd.read_csv(rf\"{DATA_RAW}\\Floods\\GloFAS_floods.csv\")\n",
    "\n",
    "def load_population_data(bounds=None, generate=False):\n",
    "    \"\"\"\n",
    "    This function processes population data by:\n",
    "    1. Reading multiple TIFF files from the specified directory.\n",
    "    2. Extracting the year from each filename and adding it as a coordinate to the dataset.\n",
    "    3. Concatenating the datasets along the 'year' dimension into a single dataset.\n",
    "    4. Filtering the dataset to include only data within the provided geographical bounds (if any).\n",
    "    5. Cleaning the dataset by selecting the first band and removing the 'band' variable.\n",
    "    6. Optionally saving the processed raster files if the 'generate' parameter is set to True.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Processing Population data...\")\n",
    "    \n",
    "    # Select all files in GPW folder\n",
    "    files = os.listdir(GPW_PATH)\n",
    "    files = [f for f in files if f.endswith(\".tif\")]\n",
    "    \n",
    "    # Compile into a single dataset\n",
    "    dss = []\n",
    "    for f in tqdm(files):\n",
    "        \n",
    "        ds = xr.open_dataset(os.path.join(GPW_PATH, f), chunks={\"x\": 10000, \"y\": 10000})\n",
    "        ds[\"band_data\"] = ds[\"band_data\"].astype(np.uint32)\n",
    "        if bounds is not None:\n",
    "            ds = ds.sel(\n",
    "                x=slice(bounds[0], bounds[2]), y=slice(bounds[3], bounds[1])\n",
    "            )\n",
    "        if generate:\n",
    "            with ProgressBar():\n",
    "                ds.sel(band=1).drop_vars(\"band\").band_data.rio.to_raster(rf\"{DATA_PROC}\\{f.replace('.tif','_proc.tif')}\")\n",
    "                print(f\"Saved {f.replace('.tif','_proc.tif')}\")\n",
    "        \n",
    "        ds[\"year\"] = int(f.split(\"_\")[5])\n",
    "        ds = ds.set_coords('year')\n",
    "        dss += [ds]\n",
    "        \n",
    "    population = xr.concat(dss, dim=\"year\")    \n",
    "    \n",
    "    # Filter if bounds are provided\n",
    "    if bounds is not None:\n",
    "        population = population.sel(\n",
    "            x=slice(bounds[0], bounds[2]), y=slice(bounds[3], bounds[1])\n",
    "        )\n",
    "        \n",
    "    # Clean band dimension\n",
    "    population = population.sel(band=1).drop_vars([\"band\"])\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return population\n",
    "\n",
    "def load_precipitation_data():\n",
    "    \"\"\"\n",
    "    This function processes precipitation data by\n",
    "    1. Opening a NetCDF file containing ERA5 monthly precipitation data for the years 1970-2021, with SPI and SPEI\n",
    "    indices.\n",
    "    2. Chunking the data using 100x100 blocks for latitude and longitude dimensions.\n",
    "    3. Renaming the dimensions from 'latitude' to 'y' and 'longitude' to 'x'.\n",
    "\n",
    "    \"\"\"\n",
    "    era5 = xr.open_dataset(\n",
    "        rf\"{DATA_OUT}\\ERA5_monthly_1970-2021_SPI-SPEI.nc\",\n",
    "        chunks={\"latitude\": 100, \"longitude\": 100},\n",
    "    )\n",
    "    era5 = era5.rename({\"latitude\": \"y\", \"longitude\": \"x\"})\n",
    "    return\n",
    "\n",
    "def load_WB_country_data(drop_adm2_na=False):\n",
    "    \"\"\"\n",
    "    This function loads and processes World Bank country data by:\n",
    "    1. Reading a compressed file containing country data.\n",
    "    2. Merges the data by combining geometries that share the same ADMLAST_CODE, ADMLAST_NAME, ADM0_CODE,\n",
    "    and ADM0_NAME into single geometries.\n",
    "    5. Creates a unique ID for each combination of ADMLAST_CODE, ADMLAST_NAME, ADM0_CODE, and ADM0_NAME.\n",
    "    \"\"\"\n",
    "    print(\"Loading World Bank country data...\")\n",
    "    WB_country = gpd.read_file(rf\"{DATA_RAW}\\world_bank_adm2.zip\")\n",
    "    \n",
    "    # Assign nan when ADM2 is not available \n",
    "    WB_country.loc[WB_country.ADM2_NAME == \"Administrative unit not available\", \"ADM2_CODE\"] = (\n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    # Create ADM_LAST variable: ADM2_NAME if available, else ADM1_NAME\n",
    "    WB_country[\"ADMLAST_CODE\"] = WB_country.ADM2_CODE\n",
    "    WB_country[\"ADMLAST_NAME\"] = WB_country.ADM2_NAME\n",
    "    WB_country.loc[WB_country.ADM2_CODE.isnull(), \"ADMLAST_CODE\"] = WB_country.ADM1_CODE\n",
    "    WB_country.loc[ WB_country.ADM2_CODE.isnull(), \"ADMLAST_NAME\"] = WB_country.ADM1_NAME\n",
    "\n",
    "    # Dissolve by ADM_LAST and country code\n",
    "    WB_country = WB_country.dissolve(by=[\"ADMLAST_CODE\", \"ADMLAST_NAME\", \"ADM0_CODE\", \"ADM0_NAME\"]).reset_index()\n",
    "    \n",
    "    # Create ID\n",
    "    WB_country[\"ID\"] = WB_country.groupby([\"ADMLAST_CODE\", \"ADMLAST_NAME\", \"ADM0_CODE\", \"ADM0_NAME\"]).ngroup()\n",
    "    assert WB_country.ID.nunique() == WB_country.shape[0], \"ID is not unique!, there's some bug in the code...\"\n",
    "    print(\"Data loaded!\")\n",
    "    return WB_country\n",
    "\n",
    "\n",
    "def rasterize_shape_like_dataset(shape, dataset):\n",
    "    \"\"\"\n",
    "    This function rasterizes a vector dataset to match the dimensions of a reference raster dataset.\n",
    "    \"\"\"\n",
    "    print(\"Rasterizing shape...\")\n",
    "    raster = make_geocube(\n",
    "        vector_data=shape,\n",
    "        like=dataset,\n",
    "    )\n",
    "    # For some reason, like option is not working, so I have to manually add x and y\n",
    "    assert (raster[\"x\"].shape == dataset[\"x\"].shape)\n",
    "    assert (raster[\"y\"].shape == dataset[\"y\"].shape)\n",
    "    raster[\"x\"] = dataset[\"x\"]\n",
    "    raster[\"y\"] = dataset[\"y\"]\n",
    "    raster = raster.drop_vars([\"spatial_ref\"])\n",
    "    raster = raster.chunk({\"x\": 100, \"y\": 100})\n",
    "    print(\"Done!\")\n",
    "    return raster\n",
    "\n",
    "def compute_zonal_stats(dataset, shape, value_var, groupby_var, gridded_groups=None, stats_funcs=[\"sum\"], delayed=True):\n",
    "    \"\"\"\n",
    "    This function computes zonal statistics for a raster dataset based on a vector dataset.\n",
    "    1. Rasterizes the vector dataset to match the raster dataset dimensions if no pre-rasterized groups are provided.\n",
    "    2. Sets up and computes zonal statistics using the specified statistical functions.\n",
    "    3. Merges the zonal statistics with the original vector dataset based on the groupby variable.\n",
    "    4. Returns the combined DataFrame with zonal statistics.\n",
    "    \"\"\"\n",
    "    # Rasterize shape\n",
    "    if gridded_groups is None:\n",
    "        gridded_groups = rasterize_shape_like_dataset(shape[[groupby_var, \"geometry\"]], dataset)\n",
    "\n",
    "    # Compute zonal stats  \n",
    "    assert gridded_groups.chunks is not None, \"Please, chunk the dataset before computing zonal stats! (e.g. dataset.chunk({'x': 100, 'y': 100})). Otherwise, you will get a MemoryError.\"\n",
    "    assert dataset.chunks is not None, \"Please, chunk the dataset before computing zonal stats! (e.g. dataset.chunk({'x': 100, 'y': 100})). Otherwise, you will get a MemoryError.\"\n",
    "\n",
    "    print(\"Setting up zonal stats...\")\n",
    "    pop_by_adm = xrspatial.zonal.stats(gridded_groups[groupby_var], dataset[value_var], stats_funcs=stats_funcs)\n",
    "    print(\"Done! Computing zonal stats...\")    \n",
    "    if delayed:\n",
    "        return pop_by_adm\n",
    "    \n",
    "    with ProgressBar():\n",
    "        pop_by_adm = pop_by_adm.compute()\n",
    "    \n",
    "    # Format zonal_stats dataframe\n",
    "    pop_by_adm = pop_by_adm.rename(columns={\n",
    "        \"sum\": value_var,\n",
    "        \"mean\": f\"{value_var}_mean\",\n",
    "        \"zone\": groupby_var,\n",
    "    })\n",
    "    \n",
    "    result = (\n",
    "        shape[[groupby_var, \"geometry\"]]\n",
    "        .merge(pop_by_adm, on=groupby_var)\n",
    "    )\n",
    "    return result \n",
    "\n",
    "def compute_zonal_stats_over_time(dataset, shape, value_var, groupby_var, population_data=None, gridded_groups=None, stats_funcs=[\"mean\"], delayed=True):\n",
    "    \"\"\"\n",
    "    This function computes zonal statistics for a raster dataset over time based on a vector dataset.\n",
    "    1. Rasterizes the vector dataset to match the raster dataset dimensions if no pre-rasterized groups are provided.\n",
    "    2. Sets up and accumulates zonal statistics tasks for each year in the raster dataset.\n",
    "    3. If population data is provided, weights the raster values by population.\n",
    "    4. Returns the combined DataFrame with zonal statistics.\n",
    "    \"\"\"\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    # Rasterize shape\n",
    "    if gridded_groups is None:\n",
    "        gridded_groups = rasterize_shape_like_dataset(shape[[groupby_var, \"geometry\"]], dataset)\n",
    "\n",
    "    # Compute zonal stats  \n",
    "    assert gridded_groups.chunks is not None, \"Please, chunk the dataset before computing zonal stats! (e.g. dataset.chunk({'x': 100, 'y': 100})). Otherwise, you will get a MemoryError.\"\n",
    "    assert dataset.chunks is not None, \"Please, chunk the dataset before computing zonal stats! (e.g. dataset.chunk({'x': 100, 'y': 100})). Otherwise, you will get a MemoryError.\"\n",
    "    assert \"year\" in dataset.dims, \"Please, add a 'year' dimension to the dataset before computing zonal stats! (e.g. dataset = dataset.assign_coords(year=dataset.time.dt.year)).\"\n",
    " \n",
    "    print(\"Setting up zonal stats...\")\n",
    "\n",
    "    tasks = []\n",
    "    for year in tqdm(dataset[\"year\"].values):\n",
    "        dataset_year = dataset.sel(year=year).drop_vars(\"year\")\n",
    "        if population_data is not None:\n",
    "            dataset_year = dataset_year * population_data.sel(year=year, method=\"nearest\").drop_vars(\"year\")\n",
    "        else:\n",
    "            dataset_year[value_var] = dataset_year[value_var].astype(\"float32\")\n",
    "\n",
    "        tasks += [xrspatial.zonal.stats(zones=gridded_groups[groupby_var], values=dataset_year[value_var], stats_funcs=stats_funcs)]\n",
    "    if delayed:\n",
    "        return tasks\n",
    "\n",
    "    print(\"Done! Computing zonal stats...\")        \n",
    "    with ProgressBar():\n",
    "        result = dask.compute(*tasks)\n",
    "        \n",
    "    return result \n",
    "\n",
    "def compile_zonal_stats_over_time(tasks_results, shape, groupby_var, value_var):\n",
    "    \"\"\"\n",
    "    This function compiles the results of zonal statistics calculated over time into a single DataFrame.\n",
    "    1. Creates a dictionary where the keys are years (1970-2020) and the values are the zonal statistics results\n",
    "    with the 'zone' column set as the index.\n",
    "    2. Concatenates the dictionary of DataFrames into a single DataFrame with a MultiIndex that includes the years.\n",
    "    3. Resets the index, converting the levels of the index (years and zones) into columns.\n",
    "    4. Merges the compiled zonal statistics DataFrame with the original vector dataset based on the 'groupby_var'.\n",
    "    5. Returns the combined DataFrame with zonal statistics.\n",
    "    \"\"\"\n",
    "    # Compile results into a single df\n",
    "    out_dict = {year: data.set_index(\"zone\") for year, data in zip(range(1970,2021), tasks_results)}\n",
    "    df = pd.concat(out_dict)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={\"level_0\":\"year\"})\n",
    "    \n",
    "    # Format zonal_stats dataframe\n",
    "    df = df.rename(columns={\n",
    "        \"sum\": value_var,\n",
    "        \"mean\": value_var,\n",
    "        \"zone\": groupby_var,\n",
    "    })\n",
    "    \n",
    "    result = (\n",
    "        shape[[groupby_var, \"geometry\"]]\n",
    "        .merge(df, on=groupby_var)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "def process_era5_data():\n",
    "   \n",
    "    # Load ERA5 data\n",
    "    \n",
    "    # Create droughts dummies\n",
    "    \n",
    "    # Annualize series\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesa WB country Data (administrative boundaries) y GPW (population data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WB_country = load_WB_country_data()\n",
    "population = load_population_data(bounds=WB_country.total_bounds)\n",
    "\n",
    "# # Rasterize WB_country\n",
    "# WB_country_grid = rasterize_shape_like_dataset(\n",
    "#     WB_country[[\"ID\", \"geometry\"]], \n",
    "#     population\n",
    "# )\n",
    "\n",
    "# WB_country_path = rf\"E:\\client_v2_data\\WB_country_grid.nc\"\n",
    "# print(\"Saving WB_country_grid...\")\n",
    "# with ProgressBar():\n",
    "#     WB_country_grid.to_netcdf(WB_country_path)\n",
    "        \n",
    "# WB_country[[\"ID\", \"OBJECTID\", \"ADM2_CODE\", \"ADM2_NAME\", \"ADM1_CODE\", \"ADM1_NAME\", \"ADM0_CODE\", \"ADM0_NAME\", \"ADMLAST_CODE\", \"ADMLAST_NAME\", \"geometry\"]].to_feather(rf\"E:\\client_v2_data\\WB_country_IDs.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERA Base de shocks, sin interpolar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "droughts_path = rf\"{DATA_OUT}\\ERA5_droughts_yearly.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(droughts_path):\n",
    "print(\"Preparing droughts dataset...\")\n",
    "# Genera base de sequías\n",
    "era5 = xr.open_dataset(rf\"{DATA_OUT}\\ERA5_monthly_1970-2021_SPI-SPEI.nc\", chunks={'latitude': 1000, 'longitude': 1000})\n",
    "# Corrije la dimensión x, que va de 0 a 360\n",
    "era5 = era5.rename({'latitude': 'y', 'longitude': 'x'})\n",
    "era5 = utils.coordinates_from_0_360_to_180_180(era5) # FIXME: no se si esto está andando bien, pero creo que si. VERIFICAR\n",
    "\n",
    "# Calcula las sequías anuales\n",
    "spi_yearly = era5.groupby(\"time.year\").min()\n",
    "with ProgressBar():\n",
    "    spi_yearly.to_netcdf(rf\"E:\\client_v2_data\\ERA5_yearly_1970-2021_SPI-SPEI.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ofici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xarray\\backends\\plugins.py:80: RuntimeWarning: Engine 'cfgrib' loading failed:\n",
      "Cannot find the ecCodes library\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "spi_yearly = xr.open_dataset(rf\"{DATA_PROC}\\ERA5_yearly_1970-2021_SPI-SPEI.nc\", chunks={\"x\": 900, \"y\": 1800})\n",
    "\n",
    "spi_spei_vars = [var for var in spi_yearly.data_vars if \"-\" in var]\n",
    "for var in spi_spei_vars:\n",
    "    for threshold_str in [\"1_0\", \"1_5\", \"2_0\", \"2_5\"]:\n",
    "        threshold = float(threshold_str.replace(\"_\", \".\"))\n",
    "        threshold_str = threshold_str.replace(\"_\", \"\")\n",
    "        spi_yearly[f\"drought_{var}_{threshold_str}sd\"] = (spi_yearly[var] < -threshold).astype(\"bool\")\n",
    "\n",
    "spi_yearly = spi_yearly[[var for var in spi_yearly.data_vars if \"drought\" in var]]\n",
    "spi_yearly = spi_yearly.rename({\n",
    "    var: var.replace(\"drought_\", \"\").replace(\"-\", \"\") for var in spi_yearly.data_vars\n",
    "})\n",
    "# with ProgressBar():\n",
    "#     spi_yearly.to_netcdf(droughts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;x&#x27; (x: 20)&gt; Size: 160B\n",
       "array([-0.90025 , -0.800222, -0.700194, -0.600167, -0.500139, -0.400111,\n",
       "       -0.300083, -0.200056, -0.100028,  0.      ,  0.      ,  0.100028,\n",
       "        0.200056,  0.300083,  0.400111,  0.500139,  0.600167,  0.700194,\n",
       "        0.800222,  0.90025 ])\n",
       "Coordinates:\n",
       "  * x        (x) float64 160B -0.9003 -0.8002 -0.7002 ... 0.7002 0.8002 0.9003</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'x'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>x</span>: 20</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-b2d7fb53-550a-4a80-95d5-d9497026ba35' class='xr-array-in' type='checkbox' checked><label for='section-b2d7fb53-550a-4a80-95d5-d9497026ba35' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>-0.9003 -0.8002 -0.7002 -0.6002 ... 0.6002 0.7002 0.8002 0.9003</span></div><div class='xr-array-data'><pre>array([-0.90025 , -0.800222, -0.700194, -0.600167, -0.500139, -0.400111,\n",
       "       -0.300083, -0.200056, -0.100028,  0.      ,  0.      ,  0.100028,\n",
       "        0.200056,  0.300083,  0.400111,  0.500139,  0.600167,  0.700194,\n",
       "        0.800222,  0.90025 ])</pre></div></div></li><li class='xr-section-item'><input id='section-d7a59074-e27e-4745-aee0-fae6fcc34712' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d7a59074-e27e-4745-aee0-fae6fcc34712' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>x</span></div><div class='xr-var-dims'>(x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-0.9003 -0.8002 ... 0.8002 0.9003</div><input id='attrs-51579ac5-24fe-4ee5-bb80-d1e9ee5ab285' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-51579ac5-24fe-4ee5-bb80-d1e9ee5ab285' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1c2e8596-6de3-445d-834a-c5be0ccc0b0b' class='xr-var-data-in' type='checkbox'><label for='data-1c2e8596-6de3-445d-834a-c5be0ccc0b0b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-0.90025 , -0.800222, -0.700194, -0.600167, -0.500139, -0.400111,\n",
       "       -0.300083, -0.200056, -0.100028,  0.      ,  0.      ,  0.100028,\n",
       "        0.200056,  0.300083,  0.400111,  0.500139,  0.600167,  0.700194,\n",
       "        0.800222,  0.90025 ])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b079858d-628e-401f-9994-ef044fc22550' class='xr-section-summary-in' type='checkbox'  ><label for='section-b079858d-628e-401f-9994-ef044fc22550' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>x</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-f7000a56-65b2-48f7-8e64-194e5bb3b305' class='xr-index-data-in' type='checkbox'/><label for='index-f7000a56-65b2-48f7-8e64-194e5bb3b305' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ -0.9002500694637092,  -0.8002222839677415,  -0.7001944984717738,\n",
       "        -0.6001667129758061,  -0.5001389274798385, -0.40011114198387077,\n",
       "        -0.3000833564879031, -0.20005557099193538, -0.10002778549596769,\n",
       "                        0.0,                  0.0,  0.10002778549596769,\n",
       "        0.20005557099193538,   0.3000833564879031,  0.40011114198387077,\n",
       "         0.5001389274798669,   0.6001667129758346,   0.7001944984718023,\n",
       "           0.80022228396777,   0.9002500694637376],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;x&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-550d670e-0d31-4390-885c-1031268323fe' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-550d670e-0d31-4390-885c-1031268323fe' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'x' (x: 20)> Size: 160B\n",
       "array([-0.90025 , -0.800222, -0.700194, -0.600167, -0.500139, -0.400111,\n",
       "       -0.300083, -0.200056, -0.100028,  0.      ,  0.      ,  0.100028,\n",
       "        0.200056,  0.300083,  0.400111,  0.500139,  0.600167,  0.700194,\n",
       "        0.800222,  0.90025 ])\n",
       "Coordinates:\n",
       "  * x        (x) float64 160B -0.9003 -0.8002 -0.7002 ... 0.7002 0.8002 0.9003"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spi_yearly.x.sel(x=slice(-1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
