{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import test_tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from procesa_bases import load_WB_country_data\n",
    "\n",
    "PATH = \"D:\\World Bank\\CLIENT v2\"\n",
    "DATA_RAW = rf\"{PATH}\\Data\\Data_raw\"\n",
    "DATA_PROC = rf\"{PATH}\\Data\\Data_proc\"\n",
    "DATA_OUT = rf\"{PATH}\\Data\\Data_out\"\n",
    "GPW_PATH = rf\"D:\\Datasets\\Gridded Population of the World\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genera mapa con etiquetas de zona (adm0 adm1 adm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ID dataset\n",
    "gdf = gpd.read_feather(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_proc\\WB_country_IDs.feather\")\n",
    "gdf.columns = gdf.columns.str.lower()\n",
    "gdf = gdf.rename(columns={\"id\":\"ID\"}).drop(columns=\"objectid\")\n",
    "\n",
    "# Add names from the original WB adm2 dataset\n",
    "gdf_raw = load_WB_country_data()\n",
    "gdf_raw.columns = gdf_raw.columns.str.lower()\n",
    "gdf_raw = gdf_raw[[\"adm0_code\", \"adm1_code\", \"adm2_code\", \"adm0_name\", \"adm1_name\", \"adm2_name\", \"geometry\"]]\n",
    "assert gdf_raw.duplicated(subset=[\"adm0_code\", \"adm1_code\", \"adm2_code\"]).sum() == 0, \"There are duplicated entries in the raw dataset!!\"\n",
    "\n",
    "# Merge both datasets to assert that the codes are correct and consistent\n",
    "gdf = gdf.merge(gdf_raw.drop(columns=\"geometry\"), how=\"outer\", on=[\"adm0_code\", \"adm1_code\", \"adm2_code\"], indicator=True, validate=\"1:1\")\n",
    "assert (gdf._merge == \"both\").all(), \"There are problems with the merge!!\"\n",
    "gdf = gdf.drop(columns=\"_merge\")\n",
    "\n",
    "gdf.drop(columns=\"ID\").to_csv(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\for webpage\\WB_map.csv\", index=False) # Export without the ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set admin level to categorical dtype (when the dataset is expanded, it will be more memory efficient)\n",
    "gdf[\"ID\"]        = gdf[\"ID\"].astype(\"category\")\n",
    "gdf[\"adm0_code\"] = gdf[\"adm0_code\"].astype(\"category\")\n",
    "gdf[\"adm1_code\"] = gdf[\"adm1_code\"].astype(\"category\")\n",
    "gdf[\"adm2_code\"] = gdf[\"adm2_code\"].astype(\"category\")\n",
    "gdf = gdf.set_index(\"ID\")\n",
    "\n",
    "gdf = gdf.drop(columns=[\"adm0_name\",\"adm1_name\",\"adm2_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genera datos de shocks clim√°ticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_raw = gpd.read_file(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_raw\\world_bank_adm2\\world_bank_adm2.shp\")\n",
    "gdf_raw.columns = gdf_raw.columns.str.lower()\n",
    "gdf_raw = gdf_raw[[\"adm0_code\", \"adm1_code\", \"adm2_code\", \"adm0_name\", \"adm1_name\", \"adm2_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "\n",
    "def expand_dataset(df, gdf):\n",
    "                    \n",
    "    # Collect all dimension values from df\n",
    "    all_years      = df.index.get_level_values(\"year\").categories\n",
    "    all_variables  = df.index.get_level_values(\"variable\").categories\n",
    "    all_thresholds = df.index.get_level_values(\"threshold\").categories\n",
    "    all_measures   = df.index.get_level_values(\"measure\").categories\n",
    "    all_regions    = gdf.index.categories # ID is the index of gdf\n",
    "\n",
    "    # Convert each list to a small DataFrame\n",
    "    df_years      = pd.DataFrame({'year': all_years}, dtype='category')\n",
    "    df_variables  = pd.DataFrame({'variable': all_variables}, dtype='category')\n",
    "    df_thresholds = pd.DataFrame({'threshold': all_thresholds}, dtype='category')\n",
    "    df_measures   = pd.DataFrame({'measure': all_measures}, dtype='category')\n",
    "    df_regions    = pd.DataFrame({'ID': all_regions}, dtype='category')\n",
    "\n",
    "    # Step-by-step merges using how='cross'\n",
    "    df_temp = df_years.merge(df_variables, how='cross')\n",
    "    df_temp = df_temp.merge(df_regions, how='cross')\n",
    "    df_temp = df_temp.merge(df_thresholds, how='cross')\n",
    "    df_temp = df_temp.merge(df_measures, how='cross')\n",
    "    expanded_without_data = df_temp.set_index([\"ID\", \"year\", \"variable\", \"threshold\", \"measure\"])\n",
    "    \n",
    "    # add admcodes to the expanded set\n",
    "    expanded_without_data = expanded_without_data.join(\n",
    "        gdf.drop(columns=[\"geometry\"]),\n",
    "        how=\"left\",\n",
    "        on=\"ID\",\n",
    "        validate=\"m:1\"\n",
    "    )\n",
    "    \n",
    "    # Merge original data (df) onto the expanded set\n",
    "    expanded_with_data = expanded_without_data.join(\n",
    "        df,\n",
    "        how=\"left\",\n",
    "        validate=\"1:1\",\n",
    "        rsuffix=\"_y\"\n",
    "    ).reset_index().drop(columns=\"ID\")\n",
    "    \n",
    "    expanded_with_data = test_tools.assert_correct_admcodes(expanded_with_data)        \n",
    "\n",
    "    return expanded_with_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "## Generados Nico\n",
    "# Set dtypes to make this loading efficient\n",
    "dtypes = {\"year\": np.int16, \"variable\":\"category\", \"threshold\":\"category\", \"area_affected\":np.float32, \"population_affected\":np.float32, \"ID\":np.int64}# \"adm2_code\": np.int16, \"adm1_code\": np.int16, \"adm0_code\": np.int16,\n",
    "\n",
    "for shock in [\"floods\", \"drought\", \"hurricanes\", \"intenserain\", \"heatwaves\", \"coldwaves\"]:\n",
    "    print(shock)\n",
    "    df = pd.read_csv(\n",
    "        rf\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\WB_{shock}_long.csv\",\n",
    "        dtype=dtypes, \n",
    "        usecols=dtypes.keys(),\n",
    "    )\n",
    "        \n",
    "    # Set ID to categorical dtype (this is after loading as int to match with the categories of gdf)\n",
    "    df[\"ID\"] = df[\"ID\"].astype(\"category\")\n",
    "    \n",
    "    # Reshape to long format\n",
    "    df = df.melt(id_vars=[\"ID\", \"year\", \"variable\", \"threshold\"], var_name=\"measure\", value_name=\"value\")\n",
    "\n",
    "    # Set categorical and index to make faster merges\n",
    "    df[\"measure\"] = df[\"measure\"].astype(\"category\")\n",
    "    df[\"year\"] = df[\"year\"].astype(\"category\")\n",
    "    df = df.set_index([\"ID\"])    \n",
    "    \n",
    "    # Add adm0, adm1 and adm2 codes    \n",
    "    df = gdf.drop(columns=[\"geometry\"]).join(df, on=[\"ID\"], how=\"inner\", validate=\"1:m\")\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Set index to make faster merges and expand dataset\n",
    "    #   Replace columns with null categories with zeros before setting the index to make it work as expected:\n",
    "    index = [\"ID\", \"year\", \"variable\", \"threshold\", \"measure\"]\n",
    "    for col in index:\n",
    "        if (df[col].dtype == \"category\"):\n",
    "            if (df[col].cat.categories.shape[0]==0):\n",
    "                df[col] = df[col].astype(float).fillna(0)\n",
    "                df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    df = df.set_index(index)\n",
    "    df = expand_dataset(df, gdf)\n",
    "\n",
    "    # Test the output\n",
    "    test_tools.assert_correct_colnames(df)\n",
    "    test_tools.assert_correct_shape(df, gdf)\n",
    "\n",
    "    # Export\n",
    "    df.to_csv(rf\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\for webpage\\WB_{shock}.csv\", index=False)\n",
    "\n",
    "    df = None\n",
    "    gc.collect()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPUMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "gdf_full = gpd.read_feather(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_proc\\IPUMS_country_IDs.feather\")\n",
    "gdf_full = gdf_full.drop(columns=[\"ID\"])\n",
    "gdf_full = gdf_full.rename(columns={\"CNTRY_CODE\":\"adm0\", \"GEOLEVEL1\":\"adm1\", \"GEOLEVEL2\":\"adm2\"})\n",
    "gdf_full[[\"adm0_name\", \"adm1_name\", \"adm2_name\"]] = \"To be filled\"\n",
    "ids = [\"adm0\", \"adm2\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Shocks\n",
    "path = r\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\HC Treatment Complete\"\n",
    "       \n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if \"HC_national_data\" in f and f.endswith(\".csv\")]\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(rf\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\HC Treatment Complete\\{file}\")\n",
    "    df[\"s3\"] = pd.NA\n",
    "    df[\"s4\"] = pd.NA\n",
    "    \n",
    "    s3cols = [\"s3a\", \"s3b\", \"s3c\", \"s3d\", \"s3f\"]\n",
    "    s4cols = [\"s4a\", \"s4b\", \"s4c\"]\n",
    "\n",
    "    for col in s3cols: \n",
    "        df[\"s3\"] = df[\"s3\"].fillna(df[col])\n",
    "        assert (df[s3cols].notna().sum(axis=1) <= 1).all(), f\"{df[(df[s3cols].notna().sum(axis=1) > 1)]}\"\n",
    "    for col in s4cols:\n",
    "        df[\"s4\"] = df[\"s4\"].fillna(df[col])\n",
    "        assert (df[s4cols].notna().sum(axis=1) <= 1).all(), f\"{df[(df[s3cols].notna().sum(axis=1) > 1)]}\"\n",
    "\n",
    "    dfs += [df]\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "for col in df.columns:\n",
    "    assert not df[col].isna().all()\n",
    "\n",
    "# Drop s3* columns\n",
    "df = df.drop(columns=[col for col in df.columns if (\"s3\" in col or \"s4\" in col) and (col != \"s3\" and col != \"s4\")])\n",
    "# Order variables\n",
    "df = df[[\"adm0\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"outcome\", \"new\", \"v\"]]\n",
    "df = df.rename(columns={\"new\":\"time\", \"v\": \"value\", \"status\":\"treatment\"})\n",
    "df.loc[df.s1 == \"Hurricane\", \"s5\"] = df.loc[df.s1 == \"Hurricane\", \"s5\"] / 100\n",
    "\n",
    "df = df.merge(gdf_full[[\"adm0\"]].drop_duplicates(), on=[\"adm0\"], validate=\"m:1\")\n",
    "print(f\"Hay datos de {df.adm0.unique().size} pa√≠ses\")\n",
    "df.to_csv(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\for webpage\\HC_national_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    \"s1\":\"Shock\",\n",
    "    \"s2\":\"Weight\",\n",
    "    \"s3\": {\n",
    "        \"Cold wave\":\"Temperature <0 ¬∞C\",\n",
    "        \"Heat wave\":\"Degrees (¬∞C)\",\n",
    "        \"Drought\":\"Drought indicator\",\n",
    "        \"Intense rain\":\"Number of days\",\n",
    "        \"Hurricane\":\"Category\"\n",
    "    },\n",
    "    \"s4\": {\n",
    "        \"Cold wave\":\"Standard Deviations from historical mean\",\n",
    "        \"Heat wave\":\"Standard Deviations from historical mean\",\n",
    "        \"Drought\":\"Standard Deviations from historical mean\",\n",
    "        \"Intense rain\":\"Rainfall (mm)\",\n",
    "        \"Hurricane\":\"Distance from center of the storm (degrees)\" # Fixme: turn to km\n",
    "    },\n",
    "    \"s5\": r\"Threshold (% affected)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Shocks\n",
    "path = r\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\HC Treatment Complete\"\n",
    "       \n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if \"HC_geodata\" in f and f.endswith(\".csv\")]\n",
    "\n",
    "# Remove previous data\n",
    "# try: \n",
    "#     os.remove(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\for webpage\\HC_geo_data.csv\") \n",
    "# except: \n",
    "#     pass\n",
    "files = files[5:]\n",
    "\n",
    "mode = \"w\" # Set mode to write in the first iteration\n",
    "for file in tqdm(files):\n",
    "    \n",
    "    df = pd.read_csv(rf\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\HC Treatment Complete\\{file}\")\n",
    "    df[\"s3\"] = pd.NA\n",
    "    df[\"s4\"] = pd.NA\n",
    "    \n",
    "    s3cols = [\"s3a\", \"s3b\", \"s3c\", \"s3d\", \"s3f\"]\n",
    "    s4cols = [\"s4a\", \"s4b\", \"s4c\"]\n",
    "\n",
    "    for col in s3cols: \n",
    "        df[\"s3\"] = df[\"s3\"].fillna(df[col])\n",
    "        assert (df[s3cols].notna().sum(axis=1) <= 1).all(), f\"{df[(df[s3cols].notna().sum(axis=1) > 1)]}\"\n",
    "    for col in s4cols:\n",
    "        df[\"s4\"] = df[\"s4\"].fillna(df[col])\n",
    "        assert (df[s4cols].notna().sum(axis=1) <= 1).all(), f\"{df[(df[s3cols].notna().sum(axis=1) > 1)]}\"\n",
    "\n",
    "    # Drop s3* columns\n",
    "    df = df.drop(columns=[col for col in df.columns if (\"s3\" in col or \"s4\" in col) and (col != \"s3\" and col != \"s4\")])\n",
    "    # Order variables\n",
    "    df = df[[\"adm0\", \"adm1\", \"adm2\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"outcome\", \"status\", \"diftime\"]]\n",
    "    df = df.rename(columns={\"status\":\"treatment_sub\", \"diftime\":\"diff\"})\n",
    "    df.loc[df.s1 == \"Hurricane\", \"s5\"] = df.loc[df.s1 == \"Hurricane\", \"s5\"] / 100\n",
    "\n",
    "    df = df.merge(gdf_full[[\"adm0\", \"adm2\"]], on=[\"adm0\", \"adm2\"], validate=\"m:1\", how=\"inner\")\n",
    "        \n",
    "    print(f\"Hay datos de {df.adm0.unique().size} pa√≠ses\")\n",
    "\n",
    "    test_tools.validate_hc_merge(df, gdf_full)\n",
    "    \n",
    "    df.to_csv(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\for webpage\\HC_geo_data.csv\", index=False, mode=mode)\n",
    "\n",
    "    mode = \"a\" # Set mode to append in the next iterations\n",
    "    \n",
    "    df = None\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import procesa_bases \n",
    "\n",
    "gdf_full = gpd.read_feather(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_proc\\IPUMS_country_IDs.feather\")\n",
    "gdf_full = gdf_full.drop(columns=[\"ID\"])\n",
    "\n",
    "WB_country = procesa_bases.load_WB_country_data()\n",
    "IPUMS_country = procesa_bases.load_IPUMS_country_data(WB_country, keep_name=True)\n",
    "IPUMS_country = IPUMS_country.clip(WB_country.total_bounds)\n",
    "\n",
    "assert (gdf_full.merge(IPUMS_country, on=[\"GEOLEVEL1\", \"GEOLEVEL2\", \"CNTRY_CODE\"], how=\"outer\", indicator=True, validate=\"1:1\")._merge == \"both\").all()\n",
    "\n",
    "# Rename columns to make it in the intended format\n",
    "IPUMS_country = IPUMS_country.rename(columns={\"CNTRY_CODE\":\"adm0\", \"GEOLEVEL1\":\"adm1\", \"GEOLEVEL2\":\"adm2\", \"CNTRY_NAME\":\"adm0_name\", \"ADMIN_NAME\":\"adm2_name\"})\n",
    "IPUMS_country = IPUMS_country.drop(columns=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPUMS_country.to_csv(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\for webpage\\HC_geo_map.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_raw\\button_labels.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\for webpage\\selector_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\for webpage\\HC_geo_data.csv\", nrows=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>adm0</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "      <th>adm0_name</th>\n",
       "      <th>adm2_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MULTIPOLYGON (((-66.5425262452896 -55.05752944...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>320940.0</td>\n",
       "      <td>32094002.0</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Ushuaia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MULTIPOLYGON (((-68.69252777099996 -56.5241928...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>152121.0</td>\n",
       "      <td>152121001.0</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Punta Arenas, Laguna Blanca, R√≠o Verde, San Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((-68.37408447301986 -52.8758621219392...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>320940.0</td>\n",
       "      <td>32094001.0</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>R√≠o Grande, Antarctic Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MULTIPOLYGON (((-69.2425308228391 -50.97999954...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>320780.0</td>\n",
       "      <td>32078001.0</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Guer Aike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MULTIPOLYGON (((-68.43839263900891 -50.0804176...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>320780.0</td>\n",
       "      <td>32078003.0</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Corpen Aike, Lago Argentino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15704</th>\n",
       "      <td>POLYGON ((84.51512909000007 62.15299225000004,...</td>\n",
       "      <td>643.0</td>\n",
       "      <td>643072.0</td>\n",
       "      <td>643072.0</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Khanty-Mansi Autonomous District - Yugra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15705</th>\n",
       "      <td>MULTIPOLYGON (((72.12913513200002 66.202468872...</td>\n",
       "      <td>643.0</td>\n",
       "      <td>643074.0</td>\n",
       "      <td>643074.0</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Yamalo-Nenets Autonomous District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15706</th>\n",
       "      <td>POLYGON ((65.48471069000004 68.36360931000003,...</td>\n",
       "      <td>643.0</td>\n",
       "      <td>643087.0</td>\n",
       "      <td>643087.0</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Komi Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15707</th>\n",
       "      <td>MULTIPOLYGON (((54.17255401600008 68.186668396...</td>\n",
       "      <td>643.0</td>\n",
       "      <td>643013.0</td>\n",
       "      <td>643013.0</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Nenets Autonomous District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15708</th>\n",
       "      <td>MULTIPOLYGON (((40.25944519000015 64.558609009...</td>\n",
       "      <td>643.0</td>\n",
       "      <td>643011.0</td>\n",
       "      <td>643011.0</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Arkhangelsk Oblast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15709 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                geometry   adm0      adm1  \\\n",
       "0      MULTIPOLYGON (((-66.5425262452896 -55.05752944...   32.0  320940.0   \n",
       "1      MULTIPOLYGON (((-68.69252777099996 -56.5241928...  152.0  152121.0   \n",
       "2      POLYGON ((-68.37408447301986 -52.8758621219392...   32.0  320940.0   \n",
       "3      MULTIPOLYGON (((-69.2425308228391 -50.97999954...   32.0  320780.0   \n",
       "4      MULTIPOLYGON (((-68.43839263900891 -50.0804176...   32.0  320780.0   \n",
       "...                                                  ...    ...       ...   \n",
       "15704  POLYGON ((84.51512909000007 62.15299225000004,...  643.0  643072.0   \n",
       "15705  MULTIPOLYGON (((72.12913513200002 66.202468872...  643.0  643074.0   \n",
       "15706  POLYGON ((65.48471069000004 68.36360931000003,...  643.0  643087.0   \n",
       "15707  MULTIPOLYGON (((54.17255401600008 68.186668396...  643.0  643013.0   \n",
       "15708  MULTIPOLYGON (((40.25944519000015 64.558609009...  643.0  643011.0   \n",
       "\n",
       "              adm2  adm0_name  \\\n",
       "0       32094002.0  Argentina   \n",
       "1      152121001.0      Chile   \n",
       "2       32094001.0  Argentina   \n",
       "3       32078001.0  Argentina   \n",
       "4       32078003.0  Argentina   \n",
       "...            ...        ...   \n",
       "15704     643072.0     Russia   \n",
       "15705     643074.0     Russia   \n",
       "15706     643087.0     Russia   \n",
       "15707     643013.0     Russia   \n",
       "15708     643011.0     Russia   \n",
       "\n",
       "                                               adm2_name  \n",
       "0                                                Ushuaia  \n",
       "1      Punta Arenas, Laguna Blanca, R√≠o Verde, San Gr...  \n",
       "2                        R√≠o Grande, Antarctic Argentina  \n",
       "3                                              Guer Aike  \n",
       "4                            Corpen Aike, Lago Argentino  \n",
       "...                                                  ...  \n",
       "15704           Khanty-Mansi Autonomous District - Yugra  \n",
       "15705                  Yamalo-Nenets Autonomous District  \n",
       "15706                                      Komi Republic  \n",
       "15707                         Nenets Autonomous District  \n",
       "15708                                 Arkhangelsk Oblast  \n",
       "\n",
       "[15709 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(r\"D:\\World Bank\\CLIENT v2\\Data\\Data_out\\for webpage\\HC_geo_map.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
